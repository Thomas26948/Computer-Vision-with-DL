{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tp_deep_learning_cnn_part_3_for_students.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPf2yufekv0f"
      },
      "source": [
        "\n",
        "\n",
        "> Bloc en retrait\n",
        "\n",
        "\n",
        "# Super-resolution with CNN\n",
        "\n",
        " \n",
        "## Objective:\n",
        "\n",
        "We want to implement a Convolutional Neural Network (CNN) to do image super-resolution.\n",
        "\n",
        "## Image super-resolution:\n",
        "\n",
        "The super-resolution problem can be summarised as follows. We have an image as an input, which is defined over a grid $\\{0,1,\\dots, m-1\\} \\times \\{0,1,\\dots, n-1\\}$. We define a factor $\\delta$, by which we upsample the image. The output of the super-resolution is an image defined on the grid $\\{0,\\frac{1}{\\delta},\\dots, m-1\\} \\times \\{0,\\frac{1}{\\delta},\\dots, n-1\\}$.\n",
        "\n",
        "\n",
        "## Dataset\n",
        "\n",
        "We will be using the mnist dataset for this part. This is to ensure we can obtain good results. The input data should be the subsampled version of the mnist images, subsampled by taking one out of every $\\delta$ pixels. The output data should be the normal-resolution mnist images.\n",
        "\n",
        "__IMPORTANT NOTES:__\n",
        "- We will use ```n_max=5000``` to limit the number of datapoints to go faster\n",
        "- We set $\\delta$ to 2\n",
        "\n",
        "\n",
        "We have created a function ```super_res_interpolate```, which carries out super-resolution using basic interpolation (bilinear or bicubic), with which we can compare your results visually and numerically.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5utO2_UDyKs3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c27cab9-fbb0-4b8f-ee23-9dd499161448"
      },
      "source": [
        "\n",
        "# # Load packages\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Input\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D\n",
        "from tensorflow.keras import optimizers\n",
        "from scipy import interpolate\n",
        "print(tf.keras.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcXyExW4vgmk"
      },
      "source": [
        " This function carries out a bilinear upsampling, with which we can compare our super-resolution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "np3Dj3tuqEqn"
      },
      "source": [
        "# choice of the interpolation method\n",
        "interp_method = 'linear'\n",
        "# upsampling factor\n",
        "delta = 2\n",
        "# the maximum number of data to take from mnist (to go a bit faster)\n",
        "n_max = 5000\n",
        "\n",
        "# upsample by a factor of delta\n",
        "# by definition, the new grid has a step size of 1/delta\n",
        "def super_res_interpolate(imgs_in,delta,interp_method = 'linear'):\n",
        "\timgs_out = tf.image.resize( tf.constant(imgs_in),\\\n",
        "\t\t[delta*imgs_in.shape[1],delta*imgs_in.shape[2]], method='bilinear').numpy()\n",
        "\n",
        "\treturn(imgs_out)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m00dElRdLBsa"
      },
      "source": [
        "\n",
        "# Initialisation of the dataset\n",
        "\n",
        "For the dataset, we are using MNIST Images.\n",
        "Our \"X\" are made of images whose sizes have been divided by 2.\n",
        "And the \"Y\" are made of the initial images.\n",
        "In the following code, we are processing the data in order to have the correct shape for the next part.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hfx5BxeUqKf-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc086d1b-5282-4969-f295-1426ee8521ac"
      },
      "source": [
        "\n",
        "from keras.datasets import mnist\n",
        "(X_train, Y_train_scalar), (X_test, Y_test_scalar) = mnist.load_data()\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "\n",
        "X_train = X_train[0:n_max,:,:]\n",
        "X_test = X_test[0:n_max,:,:]\n",
        "\n",
        "Y_train = X_train[...,tf.newaxis]\n",
        "Y_test = X_test[...,tf.newaxis]\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5000, 28, 28)\n",
            "(5000, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krBwfbsfx6sC",
        "outputId": "f5190d2e-c611-4e66-8be2-f7729ad96e1e"
      },
      "source": [
        "# X_train = tf.image.resize()\n",
        "X_train = X_train[...,tf.newaxis]\n",
        "X_train = tf.strided_slice(X_train,[0,0,0,0],[X_train.shape[0],28,28,1],[1,2,2,1])\n",
        "X_test = X_test[...,tf.newaxis]\n",
        "X_test = tf.strided_slice(X_test,[0,0,0,0],[X_test.shape[0],28,28,1],[1,2,2,1])\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5000, 14, 14, 1)\n",
            "(5000, 14, 14, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "st_r3OVtLuJl"
      },
      "source": [
        "# The model\n",
        "\n",
        "We are relying on a paper presented in class for the construction of the model.\n",
        "\n",
        "http://mmlab.ie.cuhk.edu.hk/projects/SRCNN.html\n",
        "\n",
        "Chao Dong, Chen Change Loy, Kaiming He, Xiaoou Tang. Learning a Deep Convolutional Network for Image Super-Resolution, in Proceedings of European Conference on Computer Vision (ECCV), 2014 \n",
        "\n",
        "So basically we are first resizing our images through an Upsampling layer.\n",
        "Then we are setting 3 CNN (2 Conv2D and 1 Conv2DTranspose).\n",
        "We are using ReLU as activation functions and SAME padding. In the last layer, we put a sigmoid in order to get a pixel between 0 and 1.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvg9eTUr0H-_"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(UpSampling2D(size=(delta,delta),data_format=\"channels_last\",interpolation='bilinear'))\n",
        "model.add(Conv2D(64,(9,9),activation='relu',padding='same'))\n",
        "model.add(Conv2D(32,(1,1),activation='relu',padding='same'))\n",
        "model.add(tf.keras.layers.Conv2DTranspose(1,(5,5),padding='same',activation='sigmoid'))\n",
        "\n",
        "model.build(input_shape=(5000,14,14,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVCOqbvR5soD"
      },
      "source": [
        "# HYPERPARAMETERS\n",
        "\n",
        "learning_rate = 0.01\n",
        "n_epochs = 100\n",
        "batch_size = 64\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYxEvUHNMoMA"
      },
      "source": [
        "Next we are compiling the model. \n",
        "We are using MeanSquaredError as the loss function. This is the one that makes the more sense in regard to the objective. \n",
        "As a matter of fact, we want to minimize the value of the pixels between the image computed and the real image.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D78EHRG354u6",
        "outputId": "58b4ff36-65b6-4a2e-fe19-db9ddad27913"
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.SGD(),\n",
        "              loss=tf.keras.losses.MeanSquaredError(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "model.fit(X_train, Y_train, epochs=n_epochs,batch_size=batch_size)\n",
        "\n",
        "score = model.evaluate(X_test, Y_test, verbose=False)\n",
        "print(\"Test set  : \", score)\n",
        "print(\" Loss : \", score[0])\n",
        "print(\" Accuracy : \", score[1])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " up_sampling2d (UpSampling2D  (5000, 28, 28, 1)        0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (5000, 28, 28, 64)        5248      \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (5000, 28, 28, 32)        2080      \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTra  (5000, 28, 28, 1)        801       \n",
            " nspose)                                                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,129\n",
            "Trainable params: 8,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "79/79 [==============================] - 3s 10ms/step - loss: 0.2056 - accuracy: 0.7253\n",
            "Epoch 2/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.1433 - accuracy: 0.8091\n",
            "Epoch 3/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.1003 - accuracy: 0.8091\n",
            "Epoch 4/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.0742 - accuracy: 0.8093\n",
            "Epoch 5/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0586 - accuracy: 0.8100\n",
            "Epoch 6/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.0485 - accuracy: 0.8100\n",
            "Epoch 7/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.0417 - accuracy: 0.8095\n",
            "Epoch 8/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0370 - accuracy: 0.8092\n",
            "Epoch 9/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0335 - accuracy: 0.8091\n",
            "Epoch 10/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0310 - accuracy: 0.8093\n",
            "Epoch 11/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0289 - accuracy: 0.8095\n",
            "Epoch 12/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0272 - accuracy: 0.8097\n",
            "Epoch 13/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.0258 - accuracy: 0.8099\n",
            "Epoch 14/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0246 - accuracy: 0.8101\n",
            "Epoch 15/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0236 - accuracy: 0.8104\n",
            "Epoch 16/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0226 - accuracy: 0.8106\n",
            "Epoch 17/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0218 - accuracy: 0.8107\n",
            "Epoch 18/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0211 - accuracy: 0.8109\n",
            "Epoch 19/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0205 - accuracy: 0.8111\n",
            "Epoch 20/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0199 - accuracy: 0.8112\n",
            "Epoch 21/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0194 - accuracy: 0.8113\n",
            "Epoch 22/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.0189 - accuracy: 0.8114\n",
            "Epoch 23/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0184 - accuracy: 0.8115\n",
            "Epoch 24/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0180 - accuracy: 0.8116\n",
            "Epoch 25/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0176 - accuracy: 0.8117\n",
            "Epoch 26/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0173 - accuracy: 0.8118\n",
            "Epoch 27/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0170 - accuracy: 0.8119\n",
            "Epoch 28/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0167 - accuracy: 0.8119\n",
            "Epoch 29/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0164 - accuracy: 0.8120\n",
            "Epoch 30/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.0161 - accuracy: 0.8121\n",
            "Epoch 31/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0159 - accuracy: 0.8121\n",
            "Epoch 32/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0157 - accuracy: 0.8122\n",
            "Epoch 33/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.0155 - accuracy: 0.8122\n",
            "Epoch 34/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0153 - accuracy: 0.8123\n",
            "Epoch 35/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0151 - accuracy: 0.8123\n",
            "Epoch 36/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0149 - accuracy: 0.8124\n",
            "Epoch 37/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0147 - accuracy: 0.8124\n",
            "Epoch 38/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0146 - accuracy: 0.8124\n",
            "Epoch 39/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0144 - accuracy: 0.8125\n",
            "Epoch 40/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.0143 - accuracy: 0.8125\n",
            "Epoch 41/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.0141 - accuracy: 0.8125\n",
            "Epoch 42/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0140 - accuracy: 0.8126\n",
            "Epoch 43/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0139 - accuracy: 0.8126\n",
            "Epoch 44/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0137 - accuracy: 0.8126\n",
            "Epoch 45/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.0136 - accuracy: 0.8126\n",
            "Epoch 46/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.0135 - accuracy: 0.8127\n",
            "Epoch 47/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0134 - accuracy: 0.8127\n",
            "Epoch 48/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0133 - accuracy: 0.8127\n",
            "Epoch 49/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.0132 - accuracy: 0.8127\n",
            "Epoch 50/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0131 - accuracy: 0.8128\n",
            "Epoch 51/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0130 - accuracy: 0.8128\n",
            "Epoch 52/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0129 - accuracy: 0.8128\n",
            "Epoch 53/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0128 - accuracy: 0.8128\n",
            "Epoch 54/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0127 - accuracy: 0.8128\n",
            "Epoch 55/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0127 - accuracy: 0.8128\n",
            "Epoch 56/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0126 - accuracy: 0.8129\n",
            "Epoch 57/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0125 - accuracy: 0.8129\n",
            "Epoch 58/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.0124 - accuracy: 0.8129\n",
            "Epoch 59/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.0124 - accuracy: 0.8129\n",
            "Epoch 60/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0123 - accuracy: 0.8129\n",
            "Epoch 61/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0122 - accuracy: 0.8129\n",
            "Epoch 62/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0121 - accuracy: 0.8130\n",
            "Epoch 63/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0121 - accuracy: 0.8130\n",
            "Epoch 64/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0120 - accuracy: 0.8130\n",
            "Epoch 65/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0120 - accuracy: 0.8130\n",
            "Epoch 66/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0119 - accuracy: 0.8130\n",
            "Epoch 67/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0118 - accuracy: 0.8130\n",
            "Epoch 68/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.0118 - accuracy: 0.8130\n",
            "Epoch 69/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.0117 - accuracy: 0.8131\n",
            "Epoch 70/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.0117 - accuracy: 0.8131\n",
            "Epoch 71/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0116 - accuracy: 0.8131\n",
            "Epoch 72/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.0116 - accuracy: 0.8131\n",
            "Epoch 73/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0115 - accuracy: 0.8131\n",
            "Epoch 74/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0115 - accuracy: 0.8131\n",
            "Epoch 75/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0114 - accuracy: 0.8131\n",
            "Epoch 76/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.0114 - accuracy: 0.8131\n",
            "Epoch 77/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0113 - accuracy: 0.8131\n",
            "Epoch 78/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0113 - accuracy: 0.8132\n",
            "Epoch 79/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0112 - accuracy: 0.8132\n",
            "Epoch 80/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0112 - accuracy: 0.8132\n",
            "Epoch 81/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0111 - accuracy: 0.8132\n",
            "Epoch 82/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0111 - accuracy: 0.8132\n",
            "Epoch 83/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0111 - accuracy: 0.8132\n",
            "Epoch 84/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.0110 - accuracy: 0.8132\n",
            "Epoch 85/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0110 - accuracy: 0.8132\n",
            "Epoch 86/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0109 - accuracy: 0.8132\n",
            "Epoch 87/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0109 - accuracy: 0.8133\n",
            "Epoch 88/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.0109 - accuracy: 0.8133\n",
            "Epoch 89/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.0108 - accuracy: 0.8133\n",
            "Epoch 90/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.0108 - accuracy: 0.8133\n",
            "Epoch 91/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0108 - accuracy: 0.8133\n",
            "Epoch 92/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0107 - accuracy: 0.8133\n",
            "Epoch 93/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0107 - accuracy: 0.8133\n",
            "Epoch 94/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0106 - accuracy: 0.8133\n",
            "Epoch 95/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.0106 - accuracy: 0.8133\n",
            "Epoch 96/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.0106 - accuracy: 0.8133\n",
            "Epoch 97/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0106 - accuracy: 0.8133\n",
            "Epoch 98/100\n",
            "79/79 [==============================] - 1s 9ms/step - loss: 0.0105 - accuracy: 0.8133\n",
            "Epoch 99/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0105 - accuracy: 0.8133\n",
            "Epoch 100/100\n",
            "79/79 [==============================] - 1s 8ms/step - loss: 0.0105 - accuracy: 0.8133\n",
            "Test set  :  [0.010904412716627121, 0.8219201564788818]\n",
            " Loss :  0.010904412716627121\n",
            " Accuracy :  0.8219201564788818\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8L1YyLu6NIOu"
      },
      "source": [
        "# Conclusion\n",
        "\n",
        "After training the model, we can see that we are getting an accuracy of 81%. The accuracy doesn't increase a lot but that's not disturbing. In fact, the accuracy is not the best way to see if 2 images looks the same. A pixel can take 256 different values. But the difference between 2 close value is not observable for human. \n",
        "That's why looking at the loss gives us more information. We can see that the loss has been divided by more than 5 so that's encouraging."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0DhZYc9N4Zu"
      },
      "source": [
        "Now we are going to compare the results of our model with the result of the function from the beginning.\n",
        "To do so, we'll look at the image, but we are also going to rely on a new metric, called Peak Signal Noise Ration (PSNR). It is introduced in the paper already cited above, and it is basically a good metric to measure the quality of an image and its compression. Usually, a bigger PSNR means an image of higher quality"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "3EPd67LaP7Uu",
        "outputId": "985f33e7-ecc2-4e1b-e5e8-f975a4fd67f6"
      },
      "source": [
        "fig,axs = plt.subplots(1,4,figsize=(15,15))\n",
        "\n",
        "i = int(np.random.random() * 4997)\n",
        "\n",
        "axs[0].imshow(X_test[i,...,0],cmap='gray')\n",
        "axs[0].set_title(\"Compressed image\")\n",
        "\n",
        "axs[1].imshow(model(X_test)[i,...,0],cmap='gray')\n",
        "axs[1].set_title(\"Image after the model\")\n",
        "\n",
        "axs[2].imshow(Y_test[i,...,0],cmap='gray')\n",
        "axs[2].set_title(\"Real image\")\n",
        "\n",
        "axs[3].imshow(super_res_interpolate(X_test,2)[i,...,0],cmap='gray')\n",
        "axs[3].set_title(\"super_res_interpolate image\")\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x1080 with 4 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2mXf0u-qP_p"
      },
      "source": [
        "We can see that the model produces an image that looks a lot like the original one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5Io47g6SFpk"
      },
      "source": [
        "def my_metric(X,Y):\n",
        "  \"\"\"\n",
        "  We are defining the PSNR metrice between 2 images.\n",
        "  \n",
        "  \"\"\"\n",
        "  return tf.reduce_mean(tf.image.psnr(X,Y , 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2aTFnwyTd0D"
      },
      "source": [
        "First, we compare the PSNR computed on our images predicted and through the super_res_interpolate function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfWhInxcT6Dp",
        "outputId": "4d7693e2-fe50-433c-ec43-7a5250d0a5b3"
      },
      "source": [
        "Y_inter_polate_pred = super_res_interpolate(X_test,2)\n",
        "Y_inter_polate_pred.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JcfD-YzSTUze",
        "outputId": "fd609cea-b848-43d0-8d1c-f46e954288a0"
      },
      "source": [
        "my_metric(model(X_test),Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=19.97584>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ze9_y4QhTXz0",
        "outputId": "61e29c44-0a8c-4e87-cae9-21cf5b476657"
      },
      "source": [
        "my_metric(Y_inter_polate_pred,Y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=16.60349>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XfGqrAiTu6D"
      },
      "source": [
        "So with our model, the PSNR on the whole dataset is 20.0dB whereas it is 16.6dB through the function. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkQrV70JT8mi"
      },
      "source": [
        "Then, we compute the Mean Squared Loss Error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmkLcgErYYEn",
        "outputId": "a3045740-a345-4c55-dec9-6b86bcd925d0"
      },
      "source": [
        "tf.math.reduce_mean(((Y_inter_polate_pred) - Y_test)**2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.022703482>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeV2k5DgLmJL",
        "outputId": "9fd9ac3f-4e33-4f0b-90c1-d3ee54ab2841"
      },
      "source": [
        "tf.math.reduce_mean((model(X_test) - Y_test)**2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.010904411>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAnD9PmgUGUh"
      },
      "source": [
        "Once again, our model is having better results (0.011 < 0.023)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FZ3b3s0UOYt"
      },
      "source": [
        "Finally, we can look at the accuracy : "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdO2uEAoNey0",
        "outputId": "387da8f2-ab23-412a-c1a8-23192ead631f"
      },
      "source": [
        "print(\"Accuracy : \", (Y_inter_polate_pred == Y_test).sum()/(5000*28*28))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy :  0.6955734693877551\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edS73bOgtdK8"
      },
      "source": [
        "The accuracy is also lower. We found 82% earlier with our model, whereas we only got 70% here."
      ]
    }
  ]
}